{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will try to predict the fixed point\n",
    "\n",
    "# stap 0: select right models (hardcoded a bit)\n",
    "# stap 1: aangezien option_1 de kleinere x-waarde heeft: beschouw alleen deze en gebruik deze als input voor option 1 en option 3\n",
    "# stap 2: Newton's method to determine fixed point\n",
    "\n",
    "\"\"\"\n",
    "This part is still hardcoded, in:\n",
    "-average_nullclines_from_modelnames()\n",
    "the modelnames are typed within\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from ast import literal_eval\n",
    "from FitzHugh_Nagumo_ps import nullcline_and_boundary, nullcline_vdot, nullcline_wdot, limit_cycle\n",
    "from Nullcine_MSE_plot import open_csv_and_return_all\n",
    "from plot_NN_ps import retrieve_model_from_name, normalize_axis_values, reverse_normalization, search_5_best_5_worst_modelnames\n",
    "from scipy.interpolate import interp1d\n",
    "import seaborn as sns\n",
    "from settings import TAU, A, B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Newton-Raphson method\n",
    "def newton_raphson_method(x, F, G):\n",
    "    F_interp = interp1d(x, F, kind='linear')\n",
    "    G_interp = interp1d(x, G, kind='linear')\n",
    "\n",
    "    # Initial guess for the intersection point\n",
    "    x0 = 0\n",
    "\n",
    "    # Max iterations before stopping:\n",
    "    max_iter = 200\n",
    "\n",
    "    # Tolerance for convergence:\n",
    "    tolerance = 1e-6\n",
    "\n",
    "    # Newton's method iteration:\n",
    "    for i in range(max_iter):\n",
    "        # call H the difference between F and G\n",
    "\n",
    "        # Evaluate H(x0) and H'(x0)\n",
    "        H_val = F_min_G(x0, F_interp, G_interp)\n",
    "        H_prime_val = F_min_G_prime(x0, F_interp, G_interp)\n",
    "        \n",
    "        # Update x0 using Newton's method\n",
    "        x1 = x0 - H_val / H_prime_val\n",
    "        \n",
    "        # Check for convergence\n",
    "        if abs(x1 - x0) < tolerance:\n",
    "            print('Succesfully Acquired Wanted Accuracy')\n",
    "            break\n",
    "        \n",
    "        # Update x0 for the next iteration\n",
    "        x0 = x1\n",
    "\n",
    "    print('The fixed point is located at', x0, F_interp(x0))\n",
    "    return x0, F_interp(x0)\n",
    "\n",
    "def F_min_G(x, F_interpol, G_interpolate):\n",
    "    return F_interpol(x) - G_interpolate(x)\n",
    "\n",
    "def F_min_G_prime(x, F_interpol, G_interpol, h=1e-6):\n",
    "    return (F_min_G(x+h, F_interpol, G_interpol) - F_min_G(x, F_interpol, G_interpol)) / h\n",
    "\n",
    "# => Searching for fixed point <=\n",
    "\n",
    "#  Extra Functions\n",
    "\n",
    "def return_partial_nullcline_from_modelname(modelname, title_extra='', plot_bool=True, df=None) -> tuple[np.ndarray, np.ndarray, pd.Series]:\n",
    "    \"\"\" Returns the nullcline on the phase space, but in option_1 region of axis value\n",
    "    df is a dataframe with one row containing everything\n",
    "\n",
    "    input:\n",
    "    title_extra:\n",
    "        Something extra in to put at the end in the title, like 'low val, high MSE'.\n",
    "    \"\"\"\n",
    "\n",
    "    if df is None:\n",
    "        absolute_path = os.path.dirname(__file__)\n",
    "        relative_path = f\"FHN_NN_loss_and_model_{TAU}.csv\"\n",
    "        csv_name = os.path.join(absolute_path, relative_path)\n",
    "        df = pd.read_csv(csv_name, converters={\"nodes\": literal_eval, \"mean_std\": literal_eval}) # literal eval returns [2,2] as list not as str\n",
    "\n",
    "    option = df[(df['modelname'] == modelname)]['option'].iloc[0]\n",
    "    mean_std = df[(df['modelname'] == modelname)]['mean_std'].iloc[0]\n",
    "    # learning_rate = df[(df['modelname'] == modelname)]['learning_rate'].iloc[0]\n",
    "    # nodes = df[(df['modelname'] == modelname)]['nodes'].iloc[0]\n",
    "    # layers = df[(df['modelname'] == modelname)]['layers'].iloc[0]\n",
    "    # max_epochs = df[(df['modelname'] == modelname)]['epoch'].iloc[-1]\n",
    "    # normalization_method = df[(df['modelname'] == modelname)]['normalization_method'].iloc[0]\n",
    "    # activation_function = df[(df['modelname'] == modelname)]['activation_function'].iloc[0]\n",
    "\n",
    "    model = retrieve_model_from_name(modelname)\n",
    "\n",
    "    # load data of nullclines in phasespace\n",
    "    amount_of_points = 500\n",
    "    axis_values_for_nullcline, exact_nullcline_values = nullcline_and_boundary('option_1', amount_of_points)\n",
    "\n",
    "    # Predict normalized data \n",
    "    input_prediction, reverse_norm_mean_std = normalize_axis_values(axis_values_for_nullcline, mean_std, option)\n",
    "    prediction_output_normalized = model.predict(input_prediction)\n",
    "    # Reverse normalize to 'normal' data\n",
    "    prediction_output_column = reverse_normalization(prediction_output_normalized, reverse_norm_mean_std)\n",
    "    prediction_output = prediction_output_column.reshape(-1)\n",
    "    \n",
    "    return (axis_values_for_nullcline, prediction_output, df)\n",
    "\n",
    "def select_5_best_validation(df, learning_rate, nodes, layers, max_epochs, option, amount):\n",
    "\n",
    "    df = open_csv_and_return_all(option, learning_rate, max_epochs, nodes, layers, amount=20)\n",
    "\n",
    "    df_sorted = df.sort_values(by=['validation'], ascending=True)\n",
    "\n",
    "    cut_off = 5\n",
    "    best_models = df_sorted.iloc[:5]['modelname'].tolist()\n",
    "\n",
    "    return best_models\n",
    "\n",
    "\n",
    "def save_mean_data(array, name):\n",
    "    absolute_path = os.path.dirname(__file__)\n",
    "    relative_path = \"mean_data_predicted_nullcline\"\n",
    "    folder_path = os.path.join(absolute_path, relative_path)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    full_path = os.path.join(folder_path, name)\n",
    "    np.save(full_path, array)\n",
    "\n",
    "\n",
    "# Main Function:\n",
    "\n",
    "def average_nullclines_from_modelnames(save):\n",
    "    \"\"\"\n",
    "    Plot the mean nullcline of 5 models for each nullcline and visualize the predicted fixed point using Newton-Raphson method.\n",
    "\n",
    "    Parameters:\n",
    "        save (bool): Indicates whether to save the plotted data.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Notes:\n",
    "        This function has been HARDCODED:\n",
    "        This function retrieves predictions from 5 best models for 'option_3' and 'option_1'. \n",
    "        For 'option_3', models with specified hyperparameters are selected and nullcline predictions are calculated.\n",
    "        For 'option_1', models with specified hyperparameters are selected based on validation performance and nullcline predictions are calculated.\n",
    "        The mean predictions for both options are plotted, along with the predicted fixed point and real fixed point.\n",
    "        Additionally, the function plots the limit cycle and nullclines for the system.\n",
    "        The nullclines (option1 and option3) are only plotted in the 'option_1' region to match predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    #  Prediction for option_3\n",
    "    best_worst_modelnames, _ = search_5_best_5_worst_modelnames(option='option_3', learning_rate=0.01, max_epochs=499, nodes=[16,16], layers=2, normalization_method='min-max', activation_function='relu')\n",
    "    modelnames = best_worst_modelnames['best models']\n",
    "\n",
    "    df = None\n",
    "\n",
    "    all_predictions = np.zeros((len(modelnames),), dtype=object)\n",
    "    for i, modelname in enumerate(modelnames):\n",
    "        (axis_value, all_predictions[i], df) =  return_partial_nullcline_from_modelname(modelname, title_extra='', plot_bool=False, df = df)\n",
    "    \n",
    "    mean_prediction_option3 = np.mean(all_predictions, axis=0)\n",
    "    plt.plot(axis_value, mean_prediction_option3, color='green', label='prediction option_3')\n",
    "    if save:\n",
    "        save_mean_data(mean_prediction_option3, 'best5_option_3_[16,16]relu_minmax_0.01_499_amount40')\n",
    "\n",
    "    # Prediction for option_1\n",
    "    modelnames = select_5_best_validation(df=df, learning_rate=0.01, nodes=[8,8], layers=2, max_epochs=99, option='option_1', amount=20)\n",
    "\n",
    "    all_predictions = np.zeros((len(modelnames),), dtype=object)\n",
    "    for i, modelname in enumerate(modelnames):\n",
    "        (axis_value, all_predictions[i], df) =  return_partial_nullcline_from_modelname(modelname, title_extra='', plot_bool=False, df = df)\n",
    "    \n",
    "    mean_prediction_option1 = np.mean(all_predictions, axis=0)\n",
    "    plt.plot(axis_value, mean_prediction_option1, color='purple', label='prediction option_3')\n",
    "    if save:\n",
    "        save_mean_data(mean_prediction_option1, 'best5_option_1_[8,8]_0.01_99_amount20')\n",
    "        # did not include an 'open' feature yet\n",
    "\n",
    "    xFP, yFP = newton_raphson_method(axis_value, mean_prediction_option1, mean_prediction_option3)\n",
    "    plt.scatter([xFP], [yFP], label='predicted fixed point', color='red')\n",
    "\n",
    "    x_real_FP = 0.40886584\n",
    "    A = 0.7\n",
    "    B = 0.8\n",
    "    y_real_FP = (x_real_FP + A) / B\n",
    "    plt.scatter([x_real_FP], [y_real_FP], color = 'b', marker='o', label='real fixed point')\n",
    "\n",
    "    # Now plotting the limit cycle together with the (real) nullclines\n",
    "    x_lc, y_lc = limit_cycle()\n",
    "    plt.plot(x_lc, y_lc, 'r-', label=f'LC = {0}')\n",
    "    # Plot Nullcines\n",
    "    # vdot\n",
    "    v = np.linspace(-2.5, 2.5, 1000)\n",
    "    plt.plot(v, nullcline_vdot(v), '--', color = \"lime\", label = r\"$w=v - (1/3)*v**3 + R * I$\"+r\" ,$\\dot{v}=0$ nullcline\")\n",
    "    # wdot\n",
    "    v = np.linspace(-2.5, 2.5, 1000)\n",
    "    plt.plot(v, nullcline_wdot(v), '--', color = \"cyan\", label = r\"$w=(v + A) / B$\"+r\" ,$\\dot{w}=0$ nullcline\")\n",
    "    \n",
    "    plt.xlabel('v (voltage)')\n",
    "    plt.ylabel('w (recovery variable)')\n",
    "    # plt.title(f'Predictions!!')\n",
    "    plt.title(f\"Phase Space: Limit Cycle and Nullclines with Predictions.\\nBest 5 of validation.\\n Option 1, lr0.01, 99, [8,8] #20\\nOption 3, lr0.01, 499, [16,16] relu min-max #40\")\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "def find_fixed_point_intersection_two_modelname(modelname_param1, modelname_param2, df):\n",
    "\n",
    "    (axis_value, predictions1, df) =  return_partial_nullcline_from_modelname(modelname_param1, title_extra='', plot_bool=False, df = df)\n",
    "\n",
    "    (axis_value, predictions2, df) =  return_partial_nullcline_from_modelname(modelname_param2, title_extra='', plot_bool=False, df = df)\n",
    "\n",
    "    xFP, yFP = newton_raphson_method(axis_value, predictions1, predictions2)\n",
    "\n",
    "    if xFP < min(axis_value) or xFP > max(axis_value):\n",
    "        assert False, f'value xFP does not satisfy min(axis value)<xFP<max(axis value): {min(axis_value)} < {xFP} < {max(axis_value)}.'\n",
    "    return xFP, yFP, df\n",
    "\n",
    "def all_fixed_point_from_best_models(best_5_modelnames_param1, best_5_modelnames_param2, df):\n",
    "    \"\"\"\n",
    "    Finds the fixed points of the 5 best models for each nullcline: so 25 points in total\n",
    "    \"\"\"\n",
    "\n",
    "    fixed_point_x_value = []\n",
    "    fixed_point_y_value = []\n",
    "    for modelname1 in best_5_modelnames_param1:\n",
    "        for modelname2 in best_5_modelnames_param2:\n",
    "            \n",
    "            x, y_arr, df = find_fixed_point_intersection_two_modelname(modelname1, modelname2, df)\n",
    "            y = float(y_arr)\n",
    "            fixed_point_x_value.append(x)\n",
    "            fixed_point_y_value.append(y)\n",
    "\n",
    "    return fixed_point_x_value, fixed_point_y_value\n",
    "\n",
    "def fixed_point_analysis_gaussian_fit():\n",
    "\n",
    "    df = None\n",
    "    if df is None:\n",
    "        # absolute_path = os.path.dirname(__file__)        \n",
    "        absolute_path = os.path.abspath('')\n",
    "        relative_path = f\"FHN_NN_loss_and_model_{TAU}.csv\"\n",
    "        csv_name = os.path.join(absolute_path, relative_path)\n",
    "        df = pd.read_csv(csv_name, converters={\"nodes\": literal_eval, \"mean_std\": literal_eval}) # literal eval returns [2,2] as list not as str\n",
    "\n",
    "    best_worst_modelnames_param1, _ = search_5_best_5_worst_modelnames(option='option_3', learning_rate=0.01, max_epochs=499, nodes=[16,16], layers=2, normalization_method='min-max', activation_function='relu')\n",
    "    best_val_modelnames_param1 = best_worst_modelnames_param1['best models']\n",
    "\n",
    "    best_worst_modelnames_param2, _ = search_5_best_5_worst_modelnames(option='option_1', learning_rate=0.01, max_epochs=499, nodes=[16,16], layers=2, normalization_method='min-max', activation_function='relu')\n",
    "    best_val_modelnames_param2 = best_worst_modelnames_param2['best models']\n",
    "\n",
    "    print(\"All Models Found, starting to search for fixed point\\n\")\n",
    "    x_values_FP, y_values_FP = all_fixed_point_from_best_models(best_val_modelnames_param1, best_val_modelnames_param2, df)\n",
    "    print(x_values_FP, y_values_FP)\n",
    "\n",
    "    x_values_sigmpoid_FP, y_values_sigmoid_FP = all_fixed_point_from_best_models('6bc4b512c04a4401b2eb80b1fb160461', best_val_modelnames_param2, df)\n",
    "\n",
    "    return x_values_FP, y_values_FP, x_values_sigmpoid_FP, y_values_sigmoid_FP\n",
    "\n",
    "def plot_fixed_points(x_values_FP, y_values_FP, x_values_sigmpoid_FP, y_values_sigmoid_FP):\n",
    "    # x = [(0.2579361321410763, 1.1974153677670007), (0.2578986349102627, 1.1973898568549572), (0.2579480258962664, 1.1974234595790076), (0.2578934446236969, 1.1973863256890236),\n",
    "    #     (0.2578982574320299, 1.197389600040953), (0.06747968602243959, 0.9593495252593581), (0.06745663612048293, 0.959331612039192), (0.06748983242644874, 0.9593574105323303),\n",
    "    #     (0.06743880905589467, 0.9593177577445627), (0.06744678671768216, 0.9593239575805654), (0.4960329062995323, 1.495030779896996), (0.49597090995841725, 1.4949890501079361),\n",
    "    #     (0.4960500537322715, 1.4950423218483153), (0.495980637494374, 1.4949955977205251), (0.49598330096963045, 1.4949973905079479), (0.21544334146371094, 1.1443004253029967),\n",
    "    #     (0.2154103272407928, 1.1442787081894892), (0.21545401069428866, 1.1443074436384597), (0.21540408674743075, 1.1442746031253468), (0.21540897416753152, 1.144277818123239),\n",
    "    #     (0.3706149332741673, 1.3382610442561138), (0.37043596011870455, 1.338066059102687), (0.37066557363020575, 1.3383162151981816), (0.37044627337859726, 1.3380772950478617),\n",
    "    #     (0.37045823893476604, 1.3380903311135184)]\n",
    "\n",
    "    # x_values_FP = [xFP for (xFP, yFP) in x]\n",
    "    # y_values_FP = [yFP for (xFP, yFP) in x]\n",
    "\n",
    "    data = pd.DataFrame({'X': x_values_FP, 'Y': y_values_FP})\n",
    "    data['Fixed Point'] = 'Predicted fixed point'\n",
    "\n",
    "    hue_color = {'Predicted fixed point': 'red'}\n",
    "    g = sns.jointplot(data=data, x='X', y='Y', hue='Fixed Point', ratio=10, palette=hue_color)\n",
    "    g.fig.set_size_inches((9.5,6))\n",
    "\n",
    "    plt.xlabel(\"Validation\")\n",
    "    plt.ylabel(\"Mean Squared Error\")\n",
    "\n",
    "    x_mean = np.mean(x_values_FP)\n",
    "    y_mean = np.mean(y_values_FP)\n",
    "\n",
    "    plt.scatter([x_mean], [y_mean], color = 'green', marker='o', label='mean fixed point')\n",
    "\n",
    "    plt.scatter([x_values_sigmpoid_FP], [y_values_sigmoid_FP], color= 'pink', marker='o', label='detailed fixed point')\n",
    "\n",
    "    # x_std = np.std(x_values_FP)\n",
    "    # y_std = np.std(y_values_FP)\n",
    "    # confidence_ellipse = plt.Rectangle((x_mean-x_std, y_mean-y_std), \n",
    "    #                                 2*x_std, 2*y_std, \n",
    "    #                                 edgecolor='b', facecolor='none', linestyle='--', label='95% CI')\n",
    "    # plt.gca().add_patch(confidence_ellipse)\n",
    "    # using distances\n",
    "    # plt.annotate('(', (x, y), xytext=(-10, 10), textcoords='offset points', fontsize=12, rotation=0)\n",
    "    # plt.annotate(')', (x_point - distance, y_point - distance * slope), xytext=(-10, 10), textcoords='offset points', fontsize=12, rotation=0)\n",
    "\n",
    "\n",
    "    # Phase Space Standard\n",
    "    x_real_FP = 0.40886584\n",
    "    A = 0.7\n",
    "    B = 0.8\n",
    "    y_real_FP = (x_real_FP + A) / B\n",
    "    plt.scatter([x_real_FP], [y_real_FP], color = 'b', marker='o', label='real fixed point')\n",
    "\n",
    "    # Print Standard Deviation between Predicted FP and real FP\n",
    "    points = [(x,y) for x,y in zip(x_values_FP, y_values_FP)]\n",
    "    std_distance = distance_deviation_calculator(x_mean, y_mean, points=points)\n",
    "    std_distance_mean_from_real = np.sqrt((x_real_FP-x_mean)**2 + (y_real_FP-y_mean)**2) / std_distance\n",
    "    print(f\"\\nOur mean point ({round(x_mean,2)}, {round(y_mean,2)}) is distance {round(std_distance_mean_from_real,2)}stds from real point ({round(x_real_FP,2)}, {round(y_real_FP,2)})\")\n",
    "\n",
    "\n",
    "    # Now plotting the limit cycle together with the (real) nullclines\n",
    "    x_lc, y_lc = limit_cycle()\n",
    "    plt.plot(x_lc, y_lc, 'r-', label=f'LC')\n",
    "    # Plot Nullcines\n",
    "    # vdot\n",
    "    v = np.linspace(-2.5, 2.5, 1000)\n",
    "    plt.plot(v, nullcline_vdot(v), '--', color = \"lime\", label = r\"$w=v - (1/3)*v**3 + R * I$\"+r\" ,$\\dot{v}=0$\")\n",
    "    # wdot\n",
    "    v = np.linspace(-2.5, 2.5, 1000)\n",
    "    plt.plot(v, nullcline_wdot(v), '--', color = \"cyan\", label = r\"$w=(v + A) / B$\"+r\" ,$\\dot{w}=0$\")\n",
    "    \n",
    "    plt.xlabel('v (voltage)')\n",
    "    plt.ylabel('w (recovery variable)')\n",
    "    # plt.title(f'Predictions!!')\n",
    "    plt.suptitle(f\"Phase Space: Limit Cycle and Nullclines with Predictions.\\nBest 5 of validation.\\n Option 1, lr0.01, 499, [16,16] relu min-max #40\\nOption 3, lr0.01, 499, [16,16] relu min-max #40\")\n",
    "    plt.grid(True)\n",
    "    plt.legend(bbox_to_anchor=(1.10, 1.0), loc='upper left')\n",
    "\n",
    "    plt.subplots_adjust(top=0.85, right=0.7) # Reduce plot to make room \n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def distance_deviation_calculator(x_mean, y_mean, points):\n",
    "    distance = []\n",
    "    for (x,y) in points[0::5]:\n",
    "        print(x,y)\n",
    "        calculated_distance = np.sqrt((x-x_mean)**2 + (y-y_mean)**2)\n",
    "        distance.append(calculated_distance)\n",
    "    return np.std(distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\jimmy\\Miniconda3\\envs\\Master-thesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3550\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[0;32mIn[13], line 4\u001b[0m\n    x_values_FP, y_values_FP, x_values_sigmpoid_FP, y_values_sigmoid_FP = fixed_point_analysis_gaussian_fit()\u001b[0m\n",
      "\u001b[0m  Cell \u001b[0;32mIn[12], line 223\u001b[0m in \u001b[0;35mfixed_point_analysis_gaussian_fit\u001b[0m\n    df = pd.read_csv(csv_name, converters={\"nodes\": literal_eval, \"mean_std\": literal_eval}) # literal eval returns [2,2] as list not as str\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\jimmy\\Miniconda3\\envs\\Master-thesis\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m in \u001b[0;35mread_csv\u001b[0m\n    return _read(filepath_or_buffer, kwds)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\jimmy\\Miniconda3\\envs\\Master-thesis\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m in \u001b[0;35m_read\u001b[0m\n    return parser.read(nrows)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\jimmy\\Miniconda3\\envs\\Master-thesis\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m in \u001b[0;35mread\u001b[0m\n    ) = self._engine.read(  # type: ignore[attr-defined]\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\jimmy\\Miniconda3\\envs\\Master-thesis\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m in \u001b[0;35mread\u001b[0m\n    chunks = self._reader.read_low_memory(nrows)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mparsers.pyx:838\u001b[0m in \u001b[0;35mpandas._libs.parsers.TextReader.read_low_memory\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mparsers.pyx:921\u001b[0m in \u001b[0;35mpandas._libs.parsers.TextReader._read_rows\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mparsers.pyx:1045\u001b[0m in \u001b[0;35mpandas._libs.parsers.TextReader._convert_column_data\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mparsers.pyx:2116\u001b[0m in \u001b[0;35mpandas._libs.parsers._apply_converter\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\jimmy\\Miniconda3\\envs\\Master-thesis\\lib\\ast.py:62\u001b[0m in \u001b[0;35mliteral_eval\u001b[0m\n    node_or_string = parse(node_or_string, mode='eval')\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32mc:\\Users\\jimmy\\Miniconda3\\envs\\Master-thesis\\lib\\ast.py:50\u001b[1;36m in \u001b[1;35mparse\u001b[1;36m\n\u001b[1;33m    return compile(source, filename, mode, flags,\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32m<unknown>:1\u001b[1;36m\u001b[0m\n\u001b[1;33m    [1\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # average_nullclines_from_modelnames(save=False)\n",
    "\n",
    "    x_values_FP, y_values_FP, x_values_sigmpoid_FP, y_values_sigmoid_FP = fixed_point_analysis_gaussian_fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    plot_fixed_points(x_values_FP, y_values_FP, x_values_sigmpoid_FP, y_values_sigmoid_FP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Master-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
